{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.Data_Loaders import get_loader\n",
    "from Conventional.Preprocessing import transforms\n",
    "from Conventional.Feature_extraction import Entropy, StdBGR, contrast_entropy, calculate_kurtosis, calculate_lbp, calculate_glcm, calculate_gabor, color_features\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from scipy.stats import skew\n",
    "from PIL import Image\n",
    "from skimage.filters import gabor\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "from skimage.feature import graycomatrix\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.filters import gabor_kernel\n",
    "from skimage import data, filters, color\n",
    "from skimage.transform import radon\n",
    "import pywt\n",
    "from skimage.transform import rescale\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from monai.data import pad_list_data_collate\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE \n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, make_scorer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_path=r\"C:\\Users\\moham\\My Files\\Education\\UDG\\CAD\\skin_binary_dataset\"\n",
    "Data_path=r\"E:/7th year/Girona courses/CAD/Project/Skin_Multi_Data\"\n",
    "\n",
    "train_loader= get_loader(Data_path,mode=\"train\",shuffle=True,transforms=transforms)\n",
    "val_loader= get_loader(Data_path,mode=\"val\",shuffle=True,transforms=transforms)\n",
    "test_loader= get_loader(Data_path,mode=\"test\",shuffle=False,transforms=transforms)\n",
    "\n",
    "features=[]\n",
    "Labels=[]\n",
    "\n",
    "features_val=[]\n",
    "Labels_val=[]\n",
    "\n",
    "features_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, batch in enumerate(train_loader):\n",
    "    for i in range(len(batch['label'])):\n",
    "        image=batch['image'][i].numpy().transpose(1, 2, 0)  # Convert to numpy for plt\n",
    "        color_feature=color_features(image)\n",
    "        # histogram_color_feature = histogram_color_features(image)\n",
    "        # dft_feature = dft_features(image)\n",
    "        # radon_feature_vector = radon_features(image)\n",
    "        # wavelet_feature_vector = wavelet_features(image)\n",
    "        # fractal_feature = fractal_dimension(image)\n",
    "        # fourier_features = fourier_region_features(image)\n",
    "        gray_level_features= calculate_glcm(image)\n",
    "        # HOG_feats=calculate_hog(image)\n",
    "        pattern=calculate_lbp(image)\n",
    "        entropy_feats=Entropy(image)\n",
    "        kurtosis_feats=calculate_kurtosis(image)\n",
    "        contrast_feats=contrast_entropy(image)\n",
    "        Gabor_feats=calculate_gabor(image)\n",
    "        combined_features = np.concatenate([np.array(entropy_feats),np.array(kurtosis_feats),np.array(color_feature),\n",
    "                                        np.array(Gabor_feats),np.array(gray_level_features),np.array(pattern),\n",
    "                                        np.array(contrast_feats)]) \n",
    "        features.append(combined_features)\n",
    "        Labels.append(f\"{batch['label'][i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, batch in enumerate(val_loader):\n",
    "    for i in range(len(batch['label'])):\n",
    "        image=batch['image'][i].numpy().transpose(1, 2, 0)  # Convert to numpy for plt\n",
    "        color_feature=color_features(image)\n",
    "        # histogram_color_feature = histogram_color_features(image)\n",
    "        # dft_feature = dft_features(image)\n",
    "        # radon_feature_vector = radon_features(image)\n",
    "        # wavelet_feature_vector = wavelet_features(image)\n",
    "        # fractal_feature = fractal_dimension(image)\n",
    "        # fourier_features = fourier_region_features(image)\n",
    "        gray_level_features= calculate_glcm(image)\n",
    "        # HOG_feats=calculate_hog(image)\n",
    "        pattern=calculate_lbp(image)\n",
    "        entropy_feats=Entropy(image)\n",
    "        kurtosis_feats=calculate_kurtosis(image)\n",
    "        contrast_feats=contrast_entropy(image)\n",
    "        Gabor_feats=calculate_gabor(image)\n",
    "        combined_features = np.concatenate([np.array(entropy_feats),np.array(kurtosis_feats),np.array(color_feature),\n",
    "                                        np.array(Gabor_feats),np.array(gray_level_features),np.array(pattern),\n",
    "                                        np.array(contrast_feats)]) \n",
    "        features_val.append(combined_features)\n",
    "        Labels_val.append(f\"{batch['label'][i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, batch in enumerate(test_loader):\n",
    "    for i in range(len(batch['image'])):\n",
    "        image=batch['image'][i].numpy().transpose(1, 2, 0)  # Convert to numpy for plt\n",
    "        color_feature=color_features(image)\n",
    "        # histogram_color_feature = histogram_color_features(image)\n",
    "        # dft_feature = dft_features(image)\n",
    "        # radon_feature_vector = radon_features(image)\n",
    "        # wavelet_feature_vector = wavelet_features(image)\n",
    "        # fractal_feature = fractal_dimension(image)\n",
    "        # fourier_features = fourier_region_features(image)\n",
    "        gray_level_features= calculate_glcm(image)\n",
    "        # HOG_feats=calculate_hog(image)\n",
    "        pattern=calculate_lbp(image)\n",
    "        entropy_feats=Entropy(image)\n",
    "        kurtosis_feats=calculate_kurtosis(image)\n",
    "        contrast_feats=contrast_entropy(image)\n",
    "        Gabor_feats=calculate_gabor(image)\n",
    "        combined_features = np.concatenate([np.array(entropy_feats),np.array(kurtosis_feats),np.array(color_feature),\n",
    "                                        np.array(Gabor_feats),np.array(gray_level_features),np.array(pattern),\n",
    "                                        np.array(contrast_feats)]) \n",
    "        features_test.append(combined_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier 5-Fold Cross-Validated Kappa: 0.8456 ± 0.0070\n",
      "SVM predicted labels shape: (2121,)\n"
     ]
    }
   ],
   "source": [
    "X_train1 = features        \n",
    "X_train2 = features_val    \n",
    "Y_train1 = Labels           \n",
    "Y_train2 = Labels_val       \n",
    "X_test = features_test      \n",
    "\n",
    "# Combine train and val\n",
    "X_train_combined = np.concatenate((X_train1, X_train2), axis=0)\n",
    "Y_train_combined = np.concatenate((Y_train1, Y_train2), axis=0)\n",
    "\n",
    "# Upsampling\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, Y_train_resampled = borderline_smote.fit_resample(X_train_combined, Y_train_combined)\n",
    "\n",
    "# Standardizing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=40)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Using best params from GridSearch on SVM\n",
    "svm_params = {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "svm = SVC(**svm_params)\n",
    "\n",
    "svm_kappa_scores = cross_val_score(svm, X_train_pca, Y_train_resampled, cv=cv, scoring=kappa_scorer)\n",
    "print(f\"SVM Classifier 5-Fold Cross-Validated Kappa: {svm_kappa_scores.mean():.4f} ± {svm_kappa_scores.std():.4f}\")\n",
    "\n",
    "# Train the final SVM model on full data\n",
    "svm.fit(X_train_pca, Y_train_resampled)\n",
    "\n",
    "# Test on the testing features\n",
    "y_pred = svm.predict(X_test_pca)\n",
    "print(\"SVM predicted labels shape:\", y_pred.shape)\n",
    "\n",
    "# Save SVM predictions to CSV without a header\n",
    "output_path = \"E:/7th year/Girona courses/CAD/Project/predictions/multiclass_svm_predictions.csv\"\n",
    "pd.DataFrame(y_pred).to_csv(output_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.83\n",
      "SVM Classifier Kappa: 0.70\n",
      "SVM Classifier F1 Score: 0.83\n",
      "Random Forest Classifier Accuracy: 0.79\n",
      "Random Forest Classifier Kappa: 0.62\n",
      "Random Forest Classifier F1 Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "X_train = features\n",
    "X_test = features_val\n",
    "Y_train = Labels\n",
    "Y_test = Labels_val\n",
    "\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "X_train_resampled, Y_train_resampled = borderline_smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "pca = PCA(n_components=40)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled) \n",
    "\n",
    "# rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=35, step=1)\n",
    "# X_train_rfe = rfe.fit_transform(X_train_scaled, Y_train_resampled)\n",
    "# X_test_rfe = rfe.transform(X_test_scaled)\n",
    "\n",
    "svm_params = {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "model = SVC(**svm_params)\n",
    "model.fit(X_train_pca, Y_train_resampled)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "kappa = cohen_kappa_score(Y_test, y_pred)\n",
    "f1 = f1_score(Y_test, y_pred, average='weighted')\n",
    "print(f\"SVM Classifier Accuracy: {accuracy:.2f}\")\n",
    "print(f\"SVM Classifier Kappa: {kappa:.2f}\")\n",
    "print(f\"SVM Classifier F1 Score: {f1:.2f}\")\n",
    "\n",
    "# class_weight={'0': 50, '1': 50, '2': 200}\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_pca, Y_train_resampled)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "kappa = cohen_kappa_score(Y_test, y_pred)\n",
    "f1 = f1_score(Y_test, y_pred, average='weighted')\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Random Forest Classifier Kappa: {kappa:.2f}\")\n",
    "print(f\"Random Forest Classifier F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Grid search (Don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVM Classifier Accuracy: 0.80\n",
      "SVM Classifier Kappa: 0.64\n",
      "SVM Classifier F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define training and test sets\n",
    "# X_train = features\n",
    "# X_test = features_val\n",
    "# Y_train = Labels\n",
    "# Y_test = Labels_val\n",
    "\n",
    "# # Apply Borderline-SMOTE for oversampling\n",
    "# borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "# X_train_resampled, Y_train_resampled = borderline_smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# # Standard scaling of features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=70)\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# # Define the parameter grid for SVM\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "\n",
    "# # Initialize the SVM model and grid search\n",
    "# svm = SVC()\n",
    "# grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# # Fit grid search\n",
    "# grid_search.fit(X_train_pca, Y_train_resampled)\n",
    "\n",
    "# # Get the best model and make predictions\n",
    "# best_svm = grid_search.best_estimator_\n",
    "# y_pred = best_svm.predict(X_test_pca)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(Y_test, y_pred)\n",
    "# kappa = cohen_kappa_score(Y_test, y_pred)\n",
    "# f1 = f1_score(Y_test, y_pred, average='weighted')\n",
    "# print(f\"Best SVM Parameters: {grid_search.best_params_}\")\n",
    "# print(f\"SVM Classifier Accuracy: {accuracy:.2f}\")\n",
    "# print(f\"SVM Classifier Kappa: {kappa:.2f}\")\n",
    "# print(f\"SVM Classifier F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting techniques (depricated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results:\n",
      "Accuracy: 0.76\n",
      "Kappa: 0.58\n",
      "F1 Score: 0.77\n",
      "\n",
      "CatBoost Results:\n",
      "Accuracy: 0.71\n",
      "Kappa: 0.51\n",
      "F1 Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# # Prepare training and test sets\n",
    "# X_train = features\n",
    "# X_test = features_val\n",
    "# Y_train = Labels\n",
    "# Y_test = Labels_val\n",
    "\n",
    "# # Ensure Y_train and Y_test are integer arrays\n",
    "# Y_train = np.array(Y_train, dtype=int)\n",
    "# Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "# # Apply Borderline-SMOTE for oversampling\n",
    "# borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "# X_train_resampled, Y_train_resampled = borderline_smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# # Standard scaling of features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=35)\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# # 1. XGBoost Model\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=5, n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# xgb_model.fit(X_train_pca, Y_train_resampled)\n",
    "# y_pred_xgb = xgb_model.predict(X_test_pca)\n",
    "\n",
    "# accuracy_xgb = accuracy_score(Y_test, y_pred_xgb)\n",
    "# kappa_xgb = cohen_kappa_score(Y_test, y_pred_xgb)\n",
    "# f1_xgb = f1_score(Y_test, y_pred_xgb, average='weighted')\n",
    "# print(\"XGBoost Results:\")\n",
    "# print(f\"Accuracy: {accuracy_xgb:.2f}\")\n",
    "# print(f\"Kappa: {kappa_xgb:.2f}\")\n",
    "# print(f\"F1 Score: {f1_xgb:.2f}\\n\")\n",
    "\n",
    "# # 2. CatBoost Model\n",
    "# cat_model = CatBoostClassifier(max_depth=5, n_estimators=100, learning_rate=0.1, random_state=42, verbose=0)\n",
    "# cat_model.fit(X_train_pca, Y_train_resampled)\n",
    "# y_pred_cat = cat_model.predict(X_test_pca)\n",
    "\n",
    "# accuracy_cat = accuracy_score(Y_test, y_pred_cat)\n",
    "# kappa_cat = cohen_kappa_score(Y_test, y_pred_cat)\n",
    "# f1_cat = f1_score(Y_test, y_pred_cat, average='weighted')\n",
    "# print(\"CatBoost Results:\")\n",
    "# print(f\"Accuracy: {accuracy_cat:.2f}\")\n",
    "# print(f\"Kappa: {kappa_cat:.2f}\")\n",
    "# print(f\"F1 Score: {f1_cat:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascaded Classifier: (One vs all --> Binary) (DEPRICATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search (dont run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (Class 2 vs All) Accuracy: 0.93\n",
      "Stage 1 (Class 2 vs All) Kappa: 0.06\n",
      "Stage 1 (Class 2 vs All) F1 Score: 0.06\n",
      "Stage 2 (Class 0 vs Class 1) Accuracy: 0.80\n",
      "Stage 2 (Class 0 vs Class 1) Kappa: 0.62\n",
      "Stage 2 (Class 0 vs Class 1) F1 Score: 0.77\n",
      "Overall Accuracy: 0.80\n",
      "Overall Kappa: 0.63\n",
      "Overall F1 Score: 0.78\n",
      "Best parameters found by Grid Search for Stage 1: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import numpy as np\n",
    "\n",
    "# # Prepare training and test sets\n",
    "# X_train = features\n",
    "# X_test = features_val\n",
    "# Y_train = Labels\n",
    "# Y_test = Labels_val\n",
    "\n",
    "# # Ensure Y_train and Y_test are integer arrays\n",
    "# Y_train = np.array(Y_train, dtype=int)\n",
    "# Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "# # Standard scaling of features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=35)\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# # Stage 1: Random Forest Model - Class 2 vs. All with Grid Search\n",
    "# Y_train_stage1 = (Y_train == 2).astype(int)\n",
    "# Y_test_stage1 = (Y_test == 2).astype(int)\n",
    "\n",
    "# # Define the parameter grid for Grid Search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# # Perform Grid Search with Cross-Validation\n",
    "# model_stage1 = RandomForestClassifier(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=model_stage1, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train_pca, Y_train_stage1)\n",
    "\n",
    "# # Use the best estimator found by Grid Search\n",
    "# best_model_stage1 = grid_search.best_estimator_\n",
    "# y_pred_stage1 = best_model_stage1.predict(X_test_pca)\n",
    "\n",
    "# # Evaluate Stage 1\n",
    "# accuracy_stage1 = accuracy_score(Y_test_stage1, y_pred_stage1)\n",
    "# kappa_stage1 = cohen_kappa_score(Y_test_stage1, y_pred_stage1)\n",
    "# f1_stage1 = f1_score(Y_test_stage1, y_pred_stage1)\n",
    "# print(f\"Stage 1 (Class 2 vs All) Accuracy: {accuracy_stage1:.2f}\")\n",
    "# print(f\"Stage 1 (Class 2 vs All) Kappa: {kappa_stage1:.2f}\")\n",
    "# print(f\"Stage 1 (Class 2 vs All) F1 Score: {f1_stage1:.2f}\")\n",
    "\n",
    "# # Stage 2: Random Forest Model - Class 0 vs. Class 1\n",
    "# X_test_stage2 = X_test_pca[y_pred_stage1 == 0]\n",
    "# Y_test_stage2 = Y_test[y_pred_stage1 == 0]\n",
    "\n",
    "# Y_train_stage2 = Y_train[Y_train != 2]\n",
    "# X_train_stage2 = X_train_pca[Y_train != 2]\n",
    "\n",
    "# model_stage2 = RandomForestClassifier(random_state=42)\n",
    "# model_stage2.fit(X_train_stage2, Y_train_stage2)\n",
    "# y_pred_stage2 = model_stage2.predict(X_test_stage2)\n",
    "\n",
    "# # Evaluate Stage 2\n",
    "# accuracy_stage2 = accuracy_score(Y_test_stage2, y_pred_stage2)\n",
    "# kappa_stage2 = cohen_kappa_score(Y_test_stage2, y_pred_stage2)\n",
    "# f1_stage2 = f1_score(Y_test_stage2, y_pred_stage2, average='weighted')\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) Accuracy: {accuracy_stage2:.2f}\")\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) Kappa: {kappa_stage2:.2f}\")\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) F1 Score: {f1_stage2:.2f}\")\n",
    "\n",
    "# # Combine predictions for overall evaluation\n",
    "# overall_predictions = np.where(y_pred_stage1 == 1, 2, -1)  # Assign Class 2 for predictions from Stage 1\n",
    "# overall_predictions[y_pred_stage1 == 0] = y_pred_stage2  # Assign Class 0 or 1 from Stage 2 predictions\n",
    "\n",
    "# # Calculate overall metrics\n",
    "# overall_accuracy = accuracy_score(Y_test, overall_predictions)\n",
    "# overall_kappa = cohen_kappa_score(Y_test, overall_predictions)\n",
    "# overall_f1 = f1_score(Y_test, overall_predictions, average='weighted')\n",
    "# print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "# print(f\"Overall Kappa: {overall_kappa:.2f}\")\n",
    "# print(f\"Overall F1 Score: {overall_f1:.2f}\")\n",
    "\n",
    "# # Print the best parameters found by Grid Search\n",
    "# print(\"Best parameters found by Grid Search for Stage 1:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascaded model with best params (depricated)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (Class 2 vs All) Accuracy: 0.93\n",
      "Stage 1 (Class 2 vs All) Kappa: 0.08\n",
      "Stage 1 (Class 2 vs All) F1 Score: 0.08\n",
      "Stage 2 (Class 0 vs Class 1) Accuracy: 0.79\n",
      "Stage 2 (Class 0 vs Class 1) Kappa: 0.61\n",
      "Stage 2 (Class 0 vs Class 1) F1 Score: 0.77\n",
      "Overall Accuracy: 0.80\n",
      "Overall Kappa: 0.61\n",
      "Overall F1 Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Prepare training and test sets\n",
    "# X_train = features\n",
    "# X_test = features_val\n",
    "# Y_train = Labels\n",
    "# Y_test = Labels_val\n",
    "\n",
    "# # Ensure Y_train and Y_test are integer arrays\n",
    "# Y_train = np.array(Y_train, dtype=int)\n",
    "# Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "# # Standard scaling of features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=35)\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# # Parameters for Random Forest models\n",
    "# rf_params = {\n",
    "#     'max_depth': 20,\n",
    "#     'min_samples_split': 2,\n",
    "#     'n_estimators': 50,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "# # Stage 1: Random Forest Model - Class 2 vs. All\n",
    "# Y_train_stage1 = (Y_train == 2).astype(int)\n",
    "# Y_test_stage1 = (Y_test == 2).astype(int)\n",
    "\n",
    "# # Train first-stage classifier\n",
    "# model_stage1 = RandomForestClassifier(**rf_params)\n",
    "# model_stage1.fit(X_train_pca, Y_train_stage1)\n",
    "# y_pred_stage1 = model_stage1.predict(X_test_pca)\n",
    "\n",
    "# # Evaluate Stage 1\n",
    "# accuracy_stage1 = accuracy_score(Y_test_stage1, y_pred_stage1)\n",
    "# kappa_stage1 = cohen_kappa_score(Y_test_stage1, y_pred_stage1)\n",
    "# f1_stage1 = f1_score(Y_test_stage1, y_pred_stage1)\n",
    "# print(f\"Stage 1 (Class 2 vs All) Accuracy: {accuracy_stage1:.2f}\")\n",
    "# print(f\"Stage 1 (Class 2 vs All) Kappa: {kappa_stage1:.2f}\")\n",
    "# print(f\"Stage 1 (Class 2 vs All) F1 Score: {f1_stage1:.2f}\")\n",
    "\n",
    "# # Stage 2: Random Forest Model - Class 0 vs. Class 1\n",
    "# X_test_stage2 = X_test_pca[y_pred_stage1 == 0]\n",
    "# Y_test_stage2 = Y_test[y_pred_stage1 == 0]\n",
    "\n",
    "# Y_train_stage2 = Y_train[Y_train != 2]\n",
    "# X_train_stage2 = X_train_pca[Y_train != 2]\n",
    "\n",
    "# model_stage2 = RandomForestClassifier(**rf_params)\n",
    "# model_stage2.fit(X_train_stage2, Y_train_stage2)\n",
    "# y_pred_stage2 = model_stage2.predict(X_test_stage2)\n",
    "\n",
    "# # Evaluate Stage 2\n",
    "# accuracy_stage2 = accuracy_score(Y_test_stage2, y_pred_stage2)\n",
    "# kappa_stage2 = cohen_kappa_score(Y_test_stage2, y_pred_stage2)\n",
    "# f1_stage2 = f1_score(Y_test_stage2, y_pred_stage2, average='weighted')\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) Accuracy: {accuracy_stage2:.2f}\")\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) Kappa: {kappa_stage2:.2f}\")\n",
    "# print(f\"Stage 2 (Class 0 vs Class 1) F1 Score: {f1_stage2:.2f}\")\n",
    "\n",
    "# # Combine predictions for overall evaluation\n",
    "# overall_predictions = np.where(y_pred_stage1 == 1, 2, -1)  # Assign Class 2 for predictions from Stage 1\n",
    "# overall_predictions[y_pred_stage1 == 0] = y_pred_stage2  # Assign Class 0 or 1 from Stage 2 predictions\n",
    "\n",
    "# # Calculate overall metrics\n",
    "# overall_accuracy = accuracy_score(Y_test, overall_predictions)\n",
    "# overall_kappa = cohen_kappa_score(Y_test, overall_predictions)\n",
    "# overall_f1 = f1_score(Y_test, overall_predictions, average='weighted')\n",
    "# print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "# print(f\"Overall Kappa: {overall_kappa:.2f}\")\n",
    "# print(f\"Overall F1 Score: {overall_f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
